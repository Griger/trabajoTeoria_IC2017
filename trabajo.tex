\documentclass[10pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{color} %Use custom colors and give color to text
\usepackage{graphicx} %Include images
\usepackage{enumerate}

\author{\textbf{Gustavo Rivas Gervilla}}
\title{\textcolor{deepblue}{\textbf{Lógica difusa para la descripción de datos}}}
\date{}

%Custom colors
\definecolor{deepblue}{rgb}{0,0,0.5}

%Custom itemize bullet
\def\labelitemi{$\blacktriangleright$}

\begin{document}
\pagenumbering{gobble} %turn off page enumeration
\maketitle
\begin{center}
\includegraphics[scale=0.5]{img/decsai}
\end{center}

\newpage

\tableofcontents

\newpage
\pagenumbering{arabic} %turn on page enumeration
\section{Introducción}

Actualmente existe una gran cantidad de información que nos llega en distintos formatos. Por ejemplo nos pueden llegar en forma de tabla o forma de serie temporal. En caso de ser usuarios expertos podremos trabajar con estos datos y obtener las conclusiones que necesitemos para completar la tarea que estemos abordando, por ejemplo aplicando técnicas de minería de datos en caso de que poseyamos el conocimiento necesario para ello.\\

Pero la información no siempre va destinada a usuarios expertos con lo realizar una análisis de los datos en bruto para obtener una información que les sea de utilidad puede resultar muy complejo o imposible para ellos. Así que elebarorar una descripción linguística en forma de texto compresible por el usuario de los datos se ha convertido en los últimos tiempos en algo fundamental.\\

Hoy en día, la tarea de generar información intendible por los usuarios usando lenguaje natural (que es al fin y al cabo el que maneja el usuario en su día a día) ha sido abordada desde dos campos: el de la generación de languaje natural (\textbf{NLG}, por sus siglas en inglés) y el de la descripción lingüística de datos (\textbf{LDD}, por sus siglas en inglés). Pese a que estos dos campos son en inicio independiente la tendencia que están siguiendo el avance en ambos los llevará finalmente a converger.\\

El campo de la NLG se centra en la creación de textos que proporcionan información contenida en diversos formatos con el propósito de que esos textos sean indistinguibles, tanto como sea posible, de uno creado por humanos. Por el otro lado, el campo de la LDD, que aparece como un a de las principales aplicaciones de la \textbf{teoría de conjuntos difusos}, proporciona resúmenes o descripciones de conjuntos de datos empleando conceptos lingüísticos definidos en forma de conjuntos difusos y particiones difusas, lo que le permite tratar con la imprecisión inherente al lenguaje natural. Aquí se remarca una capacidad muy importante de los conjuntos difusos y es que nos permiten representar conceptos que no tienen una definición precisa y que están sujetos a la subjetividad de cada persona.\\

El campo de la NLG es más antiguo que el de la LDD, este campo comenzó a desarrollarse en los 80, y pese a tener ya un tiempo de desarrollo continúa siendo un campo de investigación abierto en muchos aspectos y no hay una técnica única para abordar los problemas de generación de lenguaje natural.\\

Por otro lado la descripción lingüística de datos trata de obtener descripciones concisas e informativas de \textit{datasets} numéricos y cubre un grupo de técnicas basadas en soft computing, como las variables lingüísticas o los cuantificadores y operadores difusos. Este campo comenzó a desarrollarse con fuerza a mediados de los 90 con el avance en el campo de los conjuntos difusos, dando lugar a nuevas aplicaciones en el enfoque descriptivo del \textit{data mining}.\\

\subsection{NLG}

John Bateman describió la generación de lenguaje natural como la rama del procesamiento de lenguaje natural que trata el problema crear automáticamente con una máquina textos en lenguaje natural.\\

La demanda de textos en lenguaje natural que proporcionen todo tipo de información está aumentando actualmente. Algunos ejemplos que podemos destacar de la NLG son \textbf{genración de partes meteorológicos en diversos idiomas a partir de datos meteorológicos}, \textbf{generación de cartas de respuesta a clientes}, \textbf{generación de informes sobre el estado de recien nacidos}. Pese a que nosotros queremos hablar sobre aplicaciones de la lógica difusa en descripción lingüística de datos, comentamos estas aplicaciones ya que como te comentó anteriormente y teniendo en cuenta que en este tipo de aplicaciones se trabaja con conceptos procedentes del lenguaje natural; más tarde o más temprano la lógica difusa enriquecerá y potenciará todas las aplicaciones que hemos enumerado.\\

A continuación vamos a dar una pequeña descripción de cómo se diseña un sistema de NLG, ya que algunas de las fases que vamos a enumerar tendrán su correspondencia con el diseño de la aplicación final que vamos a comentar.

\subsubsection{Diseño de un sistema de NLG}

El diseño de un sistema de generación de lenguaje natural es algo abierto en la que no hay una guía concreta que seguir. Dependerá del propio diseñador y del problema a resolver. No obstante podemos desglosar la tarea principal que afrontará cualquiera de estos sistemas (convertir unos datos de entrada en un texto) en una serie de tareas que podríamos considerar, en mayor o menor medida, como comunes a todos los sitemas de NLG:

\begin{itemize}
\item \textbf{Determinación del contenido:} decicir qué información se ha de comunicar por medio del texto a crear.
\item \textbf{Planificación del discurso:} dar un orden y una estructura al conjunto de mensajes a verbalizar.
\item \textbf{Agrupación de oraciones:} agrupar varios mensajes en una sola oración. Esta tarea no es siempre necesaria, en tanto en cuanto cada mensaje puede ser expresado por medio de una oración de forma individual.
\item \textbf{Lexicalización:} decidir que palabras y expresiones han de usarse para expresar los conceptos y relaciones del dominio que aparecen en los mensajes.
\item \textbf{Geración de las expresiones de referencia (referring expression):} seleccionar las palabras o expresiones que identifican las entidades del dominio. Aunque puede parecer una tarea similar a la anterior, en este caso buscamos discriminar cada entidad del dominio del resto; empleando para ello tanta información como sea necesaria (siempre que se disponga de ella claro).
\item \textbf{Realización lingúística:} aplicar reglas gramaticales para producir un texto que sea sintácticamente, morfológicamente y ortográficamente correcto a partir de los elementos anteriormente generados.
\end{itemize}

\section{LDD}

Este campo, que trata de construir descripciones de datasets empleando términos lingüísticos, surge con las ideas de \textbf{Lofti A. Zadeh} y \textbf{Ronald Yager}, lo cuáles presentaron la lógica difusa como una herramienta para realizar computación desde un punto de vista lingüístico. De estas ideas proviene el paradigma de la computación con palabras (CW, por sus siglas en inglés) y su evolución más moderna, la teoría computacional de conceptos (CTP, por sus siglas en inglés) que, según el propio Zadeh, \textit{añade a los sistemas de computación tradicionales dos importantes capacidades: (a) la capacidad de precisar el significado de las palabras y las proposiciones extraídas del lenguaje natural; y (b) la capacidad de razonar y computar con palabras y proposiciones precisadas}. Aunque han surgido muchas aproximaciones basadas en CW, la más prometedora es el resumen lingúístico de datos, el cual emplean sentencias cuantificadas de forma difusa para obtener resúmenes lingüísticos.\\

Algunos dominios de aplicación en los que se ha aplicado este paradigma es el flujo de entrada de pacientes a un centro de salud, consumo doméstico de electricidad, medición de la calidad de los andares de un individuo, actividad humana basada en acelerómetros del dispositivo móvil o en el terreno de la meteorología.\\

Este es un campo de reciente aparición con lo que encontrar una técnica general capaz de generar distintos tipos de descripciones lingüísticas para cualquier tiene de dominio de aplicación es una tarea aún por completar, aunque ya se han dado algunos pasos en esta dirección. Además también es importante la creación de criterios generales sobre cómo estructuras sentencias cuantificadas para obtener descripciones más complejas o cómo construir y evaluar descripciones lingüísticas. Con lo cual, al igual que sucede en el campo de la NLG, no hay un consenso sobre cómo ha de implementarse un sistema de LDD.

\subsection{Elementos en un enfoque de descripción lingüística de datos}

El proceso de creación de una descripción lingüística puede definirse como la tarea de extraer la información más importante de unos datos de entrada produciendo una abstracción formada por términos lingüísticos. Esto es similar a la fase de determinación del contenido de los sitemas de NLG y constituye el nexo principal entre ambos campos.\\

Pues bien los elementos principales para crear una descripción lingüística son:

\begin{itemize}
\item Los \textbf{datos de entrada}.
\item \textbf{Variables lingüísticas} que se definen en el dominio de la variable de entrada como conjuntos difusos que etiquetan o categorizan ese dominio. Por ejemplo para la variable de entrada \textit{velocidad de conducción} podemos tener las etiquetas lingüísticas: \textit{adecuada, mala o ideal}.
\item \textbf{Cuantificadores difusos}.
\item \textbf{Criterio de evaluación}. El uso de variables lingüísticas y cuantificadores nos posibilitan crear una gran multitud de descripciones diferentes. Por lo tanto se hace patente la necesidad de tener un criterio para elegir la más adecuada entre ellas. Ya veremos más adelante el criterio que se empleó en la aplicación objetivo de mi TFG.
\end{itemize}

Este conjunto de elementos nos sirve para crear las descripciones lingüísticas más simples, las oraciones cuantificadas de tipo I como ``unos poco perros son marrones'' que pueden ser computadas usando un modelo de cuantificación difusa.\\

La construcción de oraciones cuantificadas y, en general, de descripciones lingüísticas, es un proceso que está muy influenciado por las técnicas difusas en las que se basa. Por lo tanto, para manejar la impreción implícita en las variables lingüísticas y las particiones de cuantificación, los algoritmos usados en el campo de LDD generan todas las posibles combinaciones de oraciones para dar lugar a todas las descripciones posibles. Entonces con el criterio de selección comentado anteriormente, todas las descripciones se ordenan y se elige la mejor de ellas, por tanto este proceso podría verse como una búsqueda guiada por la meta, como un algoritmo greedy. Por tanto tantos los algoritmos heurísticos como aquellos que hacen uso de meta-heurísticas se emplean para dirigir el proceso de búsqueda, para no optar por una búsqueda por fuerza bruta; que sería muy ineficiente.\\

\subsection{Técnicas y casos de uso}

Lo que ocurre en el campo de la LDD es que la componente teórica es mucho más fuerte que la práctica, e incluso cuando se presenta una nueva aplicación práctica se emplea mucho lenguaje matemático para formalizar la tarea de la generación de las descripciones lingüísticas.

\subsubsection{Trabajo teórico}

Uno de los principales objetivos que se abordan en este campo es el de diseñar un \textit{framework} que sea aplicable para cualquier tipo de problema de descripción en cualquier dominio, pero aún no se ha logrado alcanzar esta meta. En esta dirección tendríamos el modelo lingüístico granular de un fenómeno (GLMP por sus siglas en inglés), propuesto por Trivino y Sugeno, es una de las aproximaciones más prometedoras en este sentido. Está basado en una jerarquía de nodos interconectados llamados mapeos de percepción (PM por sus siglas en inglés), que reciben un conjunto de percepciones computacionales (CP) como entrada. Cada PM le aplica una función a las CP (por ejemplo el mínimo, el máximo, la media o alguna regla difusa) y genera nuevas CP que pasan como entrada al siguiente nivel de PM. En esta red cada CP cubre ciertos aspectos del fenómeno con un cierto grado de granularidad.\\

Otra nueva contribuciones plantean el uso de nuevos cuantificadores y nuevos métodos de evaluación para sentencias cuantificadas. Por ejemplo Díaz-Hermida explora varios aspectos teóricos como el uso de cuantificadores semi-difusos para modelar sentencias cuantificadas y describe algunos métodos genéricos para la detección de patrones.

\section{Descripción lingüística de series temporales}

En esta sección vamos a ver en algo de más profundidad una de las aplicaciones principales en el campo de la LDD, donde los conjuntos y sistemas difusos hacen aportaciones muy importantes, que la descripción lingüística de series de temporales.\\

Este enfoque se descompone en dos tareas principales, la extracción de conocimiento y un proceso de expresiones lingüísticas. El enfoque que vamos a ver incorpora como un elementos principal un modelo descriptivo el cual tiene tres piezas fundamentales: un mecanismo de formalización del conocimiento, un lenguaje de expresión y un marco de calidad.\\

Muchos profesionales en el área de las TIC tienen la tarea de dar sus usuarios conocimiento útil extraído a partir de un flujo de datos que están en constante crecimiento, en la mayoría de los casos para ayudar en problemas de decisión. En muchas ocasiones estos datos vienen en forma de series temporales, es decir, secuencias de datos procedentes de la observación de un fenómeno que están ordenados en el tiempo. Hay una gran cantidad de aplicaciones de economía, salud cardíaca y bienestar social, entre otros campos, que están relacionadas con la descripción lingüística de series temporales.\\

En muchas aplicaciones o tareas el usuario recibe una gran cantidad de información que se ven a obligados a intentar interpretar, lo cual puede ser un proceso complejo sobre todo para usuarios no expertos. Por otro lado, la interacción persona-ordenador basada en lenguaje natural es un campo que está creciendo en popularidad e importancia en las últimas décadas. Por lo tanto la descripción lingüística de datos es un campo de gran utilidad en la actualidad.\\

Como ya hemos comentado una descripción lingüística de datos expresa conocimiento extraído de datos usando lenguaje natural. La generación lingüística de datos consiste en dos tareas principales: un proceso de extracción de conocimiento que puede ser considera como un proceso de extracción de conocimientos en una base de datos, definido como un adquisición de conocimiento novedoso, útil y fácilmentente entendible a partir de los datos, y por otro lado un proceso de expresión lingüística que intenta mejorar la utilidad del conocimiento extraído y hacerlo más entendible usando lenguaje natural.\\
 
Un sistema de descripción lingüística de series temporales (GLiDTS por sus siglas en inglés) son sistemas computacionales que simulan la respuesta que daría un experto a la pregunta de qué ve o destaca en una serie temporal. Tanto el tipo de descripción lingüística obtenida como las técnicas empleadas para su obtención son muy variadas, incluso dentro del mismo dominio. Por ejemplo, una respuesta distinta se espera para la solicitud \textit{Habláme sobre cómo pasó el paciente la noche pasada}, donde se espera una descripción completa de varias series de datos de monitorización, y \textit{Háblame sobre cambios significativos en el ritmo cardíaco del paciente}, donde el objetivo es localizar segmentos de las series temporales que concuerden con patrones lingüísticos definidos como \textit{aumentando} o \textit{decreciendo rápidamente}.\\

En KDD y Aprendizaje Automático, la teoría de conjuntos difusos tiene el potencial de producir modelos que sean más comprensibles, menos complejos y más robustos, siendo especialmente útiles para representar patrones imprecisos y modelar y procesar varios tipos de imprecisión e información incompleta. En NLG, la teoría de conjuntos difusos tienen una un papel muy importante en dotar de semántica a los datos recibidos como entrada, y tratar con distintos tipos de imprecisión inherente en el lenguaje natural.

\subsection{Generación de descripciones lingüísticas de series temporales}

Ya hemos dicho que el objetivos de los sistemas de GLiDTS es simular la respuesta de un experto. Ahora bien, hay otros dos agentes que son importantes para estos sistemas: el destinatario de la información y el diseñador del sistema. Por lo tanto el proceso de generación de las expresiones lingüísticas para describir la información extraída está influenciada por las características del destinatario.\\

Así los datos recibidos serán descritos por una serie de mensajes que se generarán durantes el proceso de la generación de la descripción lingüística final. Para ello es necesario un formalismo de representación del conocimiento que represente la semántica de estos lenguajes. Según la potencia expresiva de este formalismo así será el espacio de mensajes que se podrán generar y en el que tendremos que realizar un proceso de búsqueda a fin de generar la descripción final.\\

Como ya hemos mencionado anteriormente, la presencia de un proceso de búsqueda en un espacio que puede ser muy grande, hace necesario usar una medida de calidad tanto de los mensajes como de la descripción final obtenida, de modo que el proceso de generación se guié según algún criterio de calidad. Evidentemente el concepto de calidad tiene muchos aspectos distintos que pueden influir en la medida escogida, entre otros las características o requisitos del destinatario de la descripción final.\\

Uno de los aspectos fundamentales tanto del formalismo de representación del conocimiento como del marco de calidad es el nivel de abstracción usado en las representaciones, ya que esto afecta a la percepción o a la descripción de la serie temporal que recibe el usuario. Cuanto más bajo sea el nivel de abstracción menor será la importancia de las expresiones lingüísticas y de las características del destinatario. Así, cuanto mayor sea la abstracción que sea hace sobre la serie temporal mayor será la importancia de los aspectos de usabilidad, novedad, inteligibilidad, etc.\\

Hay que tener en cuenta que, dado que el objetivo es simular la respuesta de un experto a una determinada pregunta acerca de un serie temporal, para generar la salida de nuestro sistema no sólo hemos de tener en cuenta la sintaxis y la semántica, también tendremos que controlar aspectos pragmáticos. Por lo tanto hemos de asegurarnos de que el texto producido de lugar a una comunicación óptima entre el sistema y el destinatario de la información. De hecho el usuario final no sólo es importante para el formalismo de representación de conocimiento que empleemos. También será importante en el lenguaje que utilicemos para expresarnos y en el marco de calidad que establezcamos en nuestro sistema.\\

Como veremos más adelante, la contribución de la teoría de conjuntos difusos y las tecnologías relacionadas con ésta es muy importante tanto en el proceso de extracción del conocimiento como en el de la genración de las expresiones para describirlo, también en la especificación del modelo descriptivo.

\subsection{Representación del conocimiento}

Uno de los aspectos fundamentales en los sitemas de GLiDTS, como ya hemos dicho antes, es elegir un mecanismo de representación del conocimientos (los mensajes) para transmitirlo al destinatario de la información. Vamos a hablar de un marco de trabajo general que es el paradigma de la Computación con Palabras y Percepciones propuesto por L.A. Zadeh, además de una teoría muy relacionada con él como es la Teoría Generalizada de la Incertidumbre.\\

En este paradigma juega un papel fundamental el concepto de protoforma. Una \textbf{protoforma} se define como un protipo abstracto. Las protoformas resultan cruciales en la formalización de el razonamiento humano y las capacidades deductivas de búsqueda, especialmente en las herramientas de descubrimientos de conocimientos basadas en lenguaje natural.\\

Vamos a ver algunas protoformas concretas que se emplean mucho en data mining y es los sistema de GLiDTS:

\begin{itemize}
\item La protoforma $X \; es \; A$, donde $A$ es una etiqueta lingüística asociada a un conjunto difuso sobre el dominio de la variable $X$.
\item La protoforma $Q \; D \; son \; A$ donde $Q$ es un cuantificador lingüístico, y $D$ y $A$ son conjuntos difusos en el mismo universo de referencia definidos por predicados difusos. Por ejemplo ``la mayoría de las veces entre las 12 y las 15 horas el precio es constante''.
\end{itemize}

\subsubsection{Formalismo}

El formalismo de representación del conocimiento se emplea para representar la semántica de los mensajes a través de la semántica de las protoformas empleadas y de los componentes que las forman, que son los elementos principales de cualquier formalismo. Por ejemplo para la oración que hemos visto anteriormente, `la mayoría de las veces entre las 12 y las 15 horas el precio es constante'', su semántica viene dada por la semántica de:

\begin{itemize}
\item La protoforma $Q \; D \; son \; A$ (la fracción de objetos de $D$ que son $A$ es $Q$).
\item El componente \textit{entre las 12 y las 15 horas} (representado por un conjunto no \textit{crisp}).
\item El componente \textit{constante} (que viene dado por un conjunto difuso sobre el rango de valores que puede tomar el ángulo que forme una línea horizontal puesta sobre la serie temporal con un cierto segmento de la misma).
\item El componente \textit{la mayoría de las veces} (un cuantificador relativo difuso representado por un subconjunto difuso no decreciente de [0,1]).
\end{itemize}

además también se emplean un conjunto de segmentos $\Omega$ sobre el que se aplican los conjuntos anteriormente definidos.\\

Muy relacionado con el concepto de protoforma y componentes está como se mide la calidad de una protoforma concreta, es decir, con qué grado esa protoforma ha de formar parte del conjunto final de mensajes que conformarán la descripción retransmitida al destinatario. Se introducen las dos definiciones siguiente:\\

\textbf{Definición 1.} El \textbf{espacio de instancias} es el conjunto de todas las protoformas que pueden contruirse empleando el formalismo de representación de conocimiento elegido.\\

\textbf{Definición 2.} El \textbf{espacio semántico} es el conjunto potencia del espacio de instancias.

Los elementos del espacio semántico representan las semanticas de toda descripción lingüística posible. El espacio de instancias consta de:

\begin{itemize}
\item Intancias del nivel de abstracción más bajo, es decir, aquellas que su medida de calidad puede obtenerse directamente a partir de los datos, como por ejemplo las instancias que se ajustan a los de tipos de protoformas presentados anteriormente.
\item Instancias de protoformas que pertenecen a niveles de abstracción mayores, estas son obtenidas a partir de protoformas de niveles más bajos empleando inferencia en la base de conocimiento experto. La medida de calidad de estas instancias se suele obtener mediantas procesos de inferencia basados en la medida de calidad de las instancias de niveles inferiores.
\end{itemize}

Además de la protoforma $X \; es \; A$ que ya hemos mencionado y que se ha usado en multitud de aplicaciones en la literatura, diferentes tipos de reglas pueden ser usadas como protoformas, incluyendo reglas difusas como $Si \; X \; es \; A,$ $entonces \; Y \; es \; B$. También se han usado patrones secuenciales representando secuencia de instancias de tipo $X \; es \; A$ para aproximar series temporales, y para representar secuencisa de acciones realizadas por un persona a lo largo de una serie temporal de datos obtenidos con algún tipo de sensor. Y además la sentencias cuantificadas son unas de las más usadas en los sitemas de GLiDTS.

\subsubsection{Técnica de extracción}

La tarea de extracción toma como entrada la serie/s temporal/es, y da como salida una colección de mensajes expresando la semántica del texto ha ser generado, usando para ello un formalismoa de representación de conocimiento previamente definido. Podemos distinguir dos tipos de operaciones que pueden emplearse en el proceso de extracción:

\begin{itemize}
\item \textbf{Generar nuevas series de datos} usando procesamiento de datos, análisis numérico de los datos e inferencia. Este paso básicamente consiste en obtener una o varias series temporales a partir de las que se le pasan como entrada. Para esto se puede aplicar sobre estas series temporales las siguientes operaciones, combinadas según se considere: transformación de los datos; obtener una serie temporal a partir de varias, a partir de algún tipo de agrupación; obtener una a partir de otra mediante las diferencias en los valores de la serie original en instantes de tiempo consecutivos; la salida de una máquina de estados finitos, pasándole como entrada los valores de la serie original; usar algunas técnicas predictivas sobre series temporales.
\item \textbf{Explorar el espacio semántico} para obtener el conjunto final de instancias que representa el mensaje final. Este proceso de búsqueda está guiado por medidas de calidad sobre las instancias individuales y/o sobre conjuntos de instancias.
\end{itemize}

La complejidad de este proceso puede venir dada por la de cualquiera de las dos operaciones anteariores. Pensemos que el espacio semántico tiene una dimensión exponencial en el número de instancias, con lo que en principio el proceso de búsqueda tendría una complejidad exponencial, no obstante, como ya hemos comentado anteriormente, pueden emplearse técnicas de optimización y heurísticas que aceleren este proceso.\\

La búsqueda exhaustiva es posible siempre que el espacio de búsqueda no sea muy grande o bien la elección de las instancias sea independiente unas de otras, de modo que el proceso de búsqueda sea lineal.\\

Por otro lado hay varias técnicas para podar el espacio de búsqueda realizando un proceso iterativo en la jerarquía de instancias según su nivel de abstracción, que consisten en dos pasos: en primer lugar buscar las instancias dentro de un nivel de abstracción determinado, comenzando en el nivel de abstracción más bajo, y después usar las instancias obtenidas para generar las instancias del nivel siguiente realizando algún proceso de inferencia. Estas técnicas asumen que las mejores instancias de un nivel pueden ser obtenidas infiriendo a partir de las mejores instancias del nivel anterior.

\subsubsection{Proceso de expresión lingüística}

Después de obtener el conjunto de instancias que representarán la semántica del mensaje final que le enviará al usuario, es necesario pasar de este conjunto a un texto que comunique el conocimiento extraído de una forma adecuada al usuario.\\

La elección de las palabras o del lenguaje que emplearemos en este texto dependerán tanto de las preferencias del diseñador del sistema como del contexto lingüístico en el que se esté trabajando. Pero el sistema debe ignorar las necesidades comunicativas específicas del receptor ya que la variedad de tipos de usuarios aumenta constantemente y representar todas las necesidades particulares de los distintos usuarios puede ser demasidado complejo. Habrá que considerar algunas restricciones que representen a un usuario medio si la aplicación está dirigida a un público muy general, si por otro lado la aplicación tienen un público muy específico entonces sí podrá tenerse en cuenta las necesidades específicas de los usuarios en este proceso.\\

Hay dos tipos de técnicas principales que se emplean en esta tarea, las llamadas \textbf{técnicas basadas en plantillas} y las técnicas \textbf{\textit{reales}}. Las primeras producen un texto simplemente manipulando cadenas, mientras que las técnicas del segundo grupo generan expresiones lingüísticas del conocimiento más sofisticadas teniendo en cuenta la planificación de oraciones y asuntos sintácticos.\\

Las técnicas usadas por la mayoría de sistemas de GLiDTS se pueden considerar como basadas en plantillas. La salidad de estos sistemas está formada por una o más instancias obtenidas realizando operaciones simples (normalmente sustitución) en uno o más patrones predefinidos que transmiten el conocimiento de un modo adecuado. Esto se debe a que la mayoría de técnicas de representación de conocimiento usan un pequeño conjunto de protoformas predefinidas.

\subsubsection{Framework de calidad}

Como ya hemos mencionado en otras ocasiones, el objetivo final de un sistema de GLiDTS es dar al usuario un texto que cubra sus necesidades. Como el número de textos que se pueden generar es enorme, tener un \textit{framework} para determinar si un texto es apropiado para un usuario determinado es indispensable. Esto es lo que se llama un \textit{framework} de calidad, y la capacidad del texto para cubrir las necesidades del usuario se llama \textbf{calidad de la descripción lingüística}.\\

Definir un \textit{framework} de calidad es una tarea muy complejada, especialmente para los sitemas de propóstico general debido a que:

\begin{itemize}
\item Una parte de la medida de calidad es claramente subjetiva y depende del contexto.
\item La calidad de una descripción lingüística tiene muchos aspectos distintos, llamados \textbf{dimensiones de calidad}, con lo que para obtener una medida de calidad buena se tendrán que medir cada uno de ellos, y ver qué importancia tienen unos respecto a otros.
\item Puede ocurrir que muchas de estas dimensiones estén fuertemente relacionadas, mientras que otras sean contradictorias entre ellas. Con lo que en general no se podrá encontrar una descripción óptima en todas las dimensiones de calidad. Así, lo sistemas de GLiDTS afrontan un problema de optimización multiobjetivo.
\end{itemize}

Las dimensiones de calidad pueden estar relacionadas con intancias individuales, conjuntos de instancias, y con diferentes aspectos de la expresión lingüística. Por lo tanto, el \textit{framework} de calidad afecta a todas las etapas del sistema de GLiDTS.\\

Dicho esto, asociada a cada dimensión hemos de dar una medida, u otro mecanismo, que nos permita decir si una descripción lingüística es incomparable, indistinguible o mejor que otra con respecto a una dimensión determinada. Es decir, asociada a cada dimensión hemos de dar una relación de precedencia en el espacio de las descripciones lingüísticas. Esto no es fácil, incluso hay dimensiones cuya medida depende del usuario al que se le dé la descripción; con lo que se necesita que antes de pasar a generar la descripción el usuario introduzca sus preferencias.

\subsubsection{Aplicaciones}

Vamos a enumerar algunas aplicaciones de este campo que, en última instancia, pueden verse como aplicaciones de la lógica difusa:

\begin{itemize}
\item En el campo del cuidado cardíaco podemos mencionar por ejemplo el sistema BT-45 que genera resúmenes textuales a partir de datos de sensores de una unidad de cuidados intensivos de recien nacidos.
\item En el campo de la meteorología tenemos el sistema SUMTIME-MOUSAM que genera pronósticos meteorlógicos a partir de datos números de predicciones meteorológicas.
\item También hay sistemas centrados en el mercado bursátil.
\item Sistemas que generar descripciones lingüísticas de un fenómeno ecológico como es el consumo doméstico de energía.
\end{itemize}

\section{Aplicación educativa a partir de expresiones de referencia}

A continuación vamos a ver con más profundidad una aplicación de la lógica difusa que surgió como objetivo final de mi Trabajo Fin de Grado. En este trabajo se desarrolló una aplicación Android para la ensañanza de conceptos básicos como la forma y el color a niños en edad preescolar. Al manejar conceptos como el color o el tamaño el uso de la lógica difusa para modelarlos es necesario. Entonces veremos los aspectos teóricos que hay bajo esta aplicación y después mostraremos algunas capturas del funcionamiento de la misma. Veremos algunas relaciones con lo que hemos contado en las secciones anteiores.

\subsection{Mecanismo de representación de conocimientos. Redes de información.}

\subsection{Búsqueda de expresiones de referencia en redes de información.}

\subsubsection{Medidad de calidad.}

\subsubsection{Diseño del algoritmo}

\subsection{Aplicación Android: Touch and Learn}
\newpage

\section{Bibliografía}
\begin{enumerate}[{[}1{]}]
\item \textbf{On the role of linguistic descriptions of data in the building of natural language generation systems.} A. Ramos-Soto, A. Bugarín y S.Barro. Elsevier. Fuzzy sets and systems. \textit{13 de Julio de 2015}.
\item \textbf{On generating linguistic descriptions of time series.} Nicolás Marín y Daniel Sánchez. Elsevier. Fuzzy sets and systems. \textit{4 de Mayo de 2015}.
\end{enumerate}
\end{document}